{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae62c34-415a-4979-a169-8b36afbe1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca027de-0250-4583-9953-28dc043b441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集条数：222352。\n"
     ]
    }
   ],
   "source": [
    "#初始化相关参数\n",
    "List=[]\n",
    "WordList1={}\n",
    "WordList2={}\n",
    "WordList3={}\n",
    "\n",
    "#读取数据集                                   共222352条\n",
    "DS=pd.read_csv('Dataset/train.tsv',sep='\\t') #156060条\n",
    "DS2=pd.read_csv('Dataset/test.tsv',sep='\\t') #66292条\n",
    "\n",
    "List += DS['Phrase'].tolist()\n",
    "List += DS2['Phrase'].tolist()\n",
    "print(\"数据集条数：\"+str(len(List))+\"。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ad5808-12f6-41e1-aee2-7a7623613f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "单token共19479个\n"
     ]
    }
   ],
   "source": [
    "#抽取单token特征集WordList1\n",
    "for phrase in List:\n",
    "    for word in phrase.split(' '):\n",
    "        littleword=word.lower() #所有字母转化为小写\n",
    "        if littleword not in WordList1:\n",
    "            WordList1[littleword]=1\n",
    "        else:\n",
    "            WordList1[littleword]+=1\n",
    "print('单token共'+str(len(WordList1))+'个')\n",
    "\n",
    "#按照涉及次数倒序排序，存储在list1.txt\n",
    "SortedList1=sorted(WordList1.items(), key = lambda x:x[1],reverse=True)\n",
    "\n",
    "#pd存储方法\n",
    "SortedList1=pd.DataFrame((word[0] for word in SortedList1),columns=['feat'])\n",
    "SortedList1.to_csv('Dataset/list1.csv')\n",
    "\n",
    "#基础存储方法（验证用）\n",
    "#with open('Dataset/list1.txt','w') as f:\n",
    "#    for word in SortedList1:\n",
    "#        f.write(word[0]+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ba9d03-82a8-43e1-a4fc-dfb24df820a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "双token共106005个\n"
     ]
    }
   ],
   "source": [
    "#抽取双token特征集WordList2\n",
    "for phrase in List:\n",
    "    phraselist=phrase.split(' ')\n",
    "    phrasenum=len(phraselist)\n",
    "    if phrasenum > 1:\n",
    "        for i in range(0,phrasenum-1):\n",
    "            #特征排序\n",
    "            if phraselist[i] < phraselist[i+1]:\n",
    "                word=phraselist[i].lower()+' '+phraselist[i+1].lower()\n",
    "            else:\n",
    "                word=phraselist[i+1].lower()+' '+phraselist[i].lower()\n",
    "            \n",
    "            if word not in WordList2:\n",
    "                WordList2[word]=1\n",
    "            else:\n",
    "                WordList2[word]+=1\n",
    "print('双token共'+str(len(WordList2))+'个')\n",
    "\n",
    "#按照涉及次数倒序排序，存储在list2.txt\n",
    "SortedList2=sorted(WordList2.items(), key = lambda x:x[1],reverse=True)\n",
    "SortedList2=pd.DataFrame((word[0] for word in SortedList2),columns=['feat'])\n",
    "SortedList2.to_csv('Dataset/list2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6228846e-0924-44ae-8c28-58e557b830fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "三token共169430个\n"
     ]
    }
   ],
   "source": [
    "#抽取三token特征集WordList3\n",
    "for phrase in List:\n",
    "    phraselist=phrase.split(' ')\n",
    "    phrasenum=len(phraselist)\n",
    "    if phrasenum > 2:\n",
    "        for i in range(0,phrasenum-2):\n",
    "            #特征排序\n",
    "            wordlist=phraselist[i:i+3]\n",
    "            wordlist.sort()\n",
    "            word=wordlist[0].lower()+' '+wordlist[1].lower()+' '+wordlist[2].lower()\n",
    "\n",
    "            if word not in WordList3:\n",
    "                WordList3[word]=1\n",
    "            else:\n",
    "                WordList3[word]+=1\n",
    "print('三token共'+str(len(WordList3))+'个')\n",
    "\n",
    "#按照涉及次数倒序排序，存储在list2.txt\n",
    "SortedList3=sorted(WordList3.items(), key = lambda x:x[1],reverse=True)\n",
    "SortedList3=pd.DataFrame((word[0] for word in SortedList3),columns=['feat'])\n",
    "SortedList3.to_csv('Dataset/list3.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a4b0b103f443abab642cb805870998419f99b3b67480212ee124b95ac521b42"
  },
  "kernelspec": {
   "display_name": "Python [conda env:deep] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
